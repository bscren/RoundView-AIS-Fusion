# ç‰ˆæœ¬ç‰¹ç‚¹:
# 1. åŸºäºROS2å¼€å‘ï¼Œè¦æ±‚è½¨è¿¹æ•°æ®åœ¨æœ¬ç¨‹åºå®Œæˆä¸åŒç›¸æœºä¹‹é—´çš„åæ ‡æ˜ å°„ï¼Œè€Œä¸æ˜¯åœ¨C++ä¸»èŠ‚ç‚¹å®Œæˆã€‚
# 2. å› æ­¤éœ€è¦è¯»å–ä¸åŒç›¸æœºçš„å†…å‚å’Œå¤–å‚
# 3. è”åŠ¨ç°æœ‰çš„JHæ‹¼æ¥ä»£ç ï¼Œå®ç°å¤šç›¸æœºæ‹¼æ¥æ˜¾ç¤ºï¼Œæ‰€ç”¨å‚æ•°éœ€è¦æ±‚ä¸JHæ‹¼æ¥ä»£ç ä¸€è‡´
# 4. utilsä¹Ÿéœ€è¦é€‚é…JHæ‹¼æ¥ä»£ç ï¼Œå¦æ–°å»ºä¸€ä¸ªutils_JHæ–‡ä»¶å¤¹
import os
import time
import imutils

import cv2
import pandas as pd
import numpy as np
import rclpy
from rclpy.node import Node
from rclpy.time import builtin_interfaces
from sensor_msgs.msg import Image
from marnav_interfaces.msg import AisBatch, Gnss, VisiableTra, VisiableTraBatch

from rclpy.qos import QoSProfile, QoSReliabilityPolicy, QoSHistoryPolicy
from cv_bridge import CvBridge
from message_filters import ApproximateTimeSynchronizer, Subscriber
import traceback # tracebackç”¨äºæ‰“å°å¼‚å¸¸ä¿¡æ¯

# CPUå¯†é›†å‹ä»»åŠ¡ï¼Œä½¿ç”¨å¤šè¿›ç¨‹å¤„ç†ï¼Œè€Œä¸æ˜¯å¤šçº¿ç¨‹å¤„ç†ï¼Œå¤šçº¿ç¨‹é€‚ç”¨äºIOå¯†é›†å‹ä»»åŠ¡
from multiprocessing import Process, Queue, cpu_count, set_start_method
import multiprocessing

from utils_JH.file_read import read_all, ais_initial, update_time, time2stamp
from utils_JH.VIS_utils import VISPRO
from utils_JH.AIS_utils import AISPRO
from utils_JH.FUS_utils import FUSPRO
from utils_JH.gen_result import gen_result
from utils_JH.draw import DRAW
from marnav_vis.config_loader import ConfigLoader

# ç”±v4çš„å¤šçº¿ç¨‹æ”¹ä¸ºv5çš„å¤šè¿›ç¨‹ï¼Œæ¯ä¸ªè¿›ç¨‹ç‹¬ç«‹å¤„ç†ä¸€å¸§: åŒ…å«AIS, VIS, FUS, DRAW

# ------------------------------------------------------
def multi_proc_worker(input_queue, output_queue, im_shape, t, max_dis, skip_interval = 1, camera_type = "normal", yolo_type = "yolo11m"):
    """
    æ¯ä¸ªè¿›ç¨‹ç‹¬ç«‹å¤„ç†ä¸€å¸§: åŒ…å«AIS, VIS, FUS, DRAW
     1. ä»è¾“å…¥é˜Ÿåˆ—è·å–ä»»åŠ¡
     2. å¤„ç†AIS, VIS, FUS, DRAW
     3. å°†ç»“æœæ”¾å…¥è¾“å‡ºé˜Ÿåˆ—
     å‚æ•°:
        input_queue: å¤šè¿›ç¨‹è¾“å…¥é˜Ÿåˆ—ï¼ŒåŒ…å«äº†:
                self.mp_input_queue[cam_topic].put({
                    "cam_idx": cam_idx,
                    "cv_image": cv_images[cam_idx],
                    "current_timestamp": current_timestamp,
                    "ais_batch": self.aisbatch_cache.copy(),
                    "camera_pos_para": self.camera_pos_para,
                    "bin_inf": self.bin_inf[cam_idx].copy() if len(self.bin_inf) > cam_idx else pd.DataFrame(),
                })
                    å…¶ä¸­:
                    camera_pos_para = {
                        "longitude": msg.longitude,
                        "latitude": msg.latitude,
                        "horizontal_orientation": horizontal_orientation,
                        "vertical_orientation": msg.vertical_orientation,
                        "camera_height": msg.camera_height,
                        'fov_hor': resp.fov_hor,
                        'fov_ver': resp.fov_ver,
                        'focal': resp.focal,
                        'fx': resp.fx,
                        'fy': resp.fy,
                        'u0': resp.u0,
                        'v0': resp.v0,
                        # ä¸‹åˆ—é™å®šäºé±¼çœ¼ç›¸æœºï¼Œæ™®é€šç›¸æœºä¸éœ€è¦
                        'k1': resp.k1,
                        'k2': resp.k2,
                        'k3': resp.k3,
                        'k4': resp.k4,
                    }


        output_queue: å¤šè¿›ç¨‹è¾“å‡ºé˜Ÿåˆ—ï¼ŒåŒ…å«äº†:
                    cam_idx,
                    image
                    timestamp 
                    updated_bin
                    time_cost
        t: æ—¶é—´é—´éš” (ms)
        camera_para: ç›¸æœºå‚æ•°å­—å…¸
        max_dis: æœ€å¤§è·ç¦»
    """
    print(f"worker process started, pid={os.getpid()}")

    aispro = AISPRO(im_shape, t)
    vispro = VISPRO(1, 0, t, yolo_type)  # æ˜¯å¦è¯»å–antiå‚æ•°å¯ä»¥è‡ªå®šä¹‰
    fuspro = FUSPRO(max_dis, im_shape, t)
    dra = DRAW(im_shape, t)

    # ç¼“å­˜ä¸Šä¸€çª—å£çš„èåˆè½¨è¿¹
    Last_Visiable_Tra = pd.DataFrame()
    # è®°å½•ä¸Šæ¬¡å¤„ç†æ—¶æ‰€å±çš„æ—¶é—´çª—å£
    last_processed_window = -1
    while True:
        start_time = time.time()
        task = input_queue.get()
        if task is None:
            break
        try:
            cam_idx = task["cam_idx"]
            cv_image = task["cv_image"]
            current_timestamp = task["current_timestamp"]
            ais_batch = task["ais_batch"]
            camera_pos_para = task["camera_pos_para"]
            bin_inf = task["bin_inf"]
            

            # è®¡ç®—å½“å‰æ—¶é—´æˆ³å±äºå“ªä¸ªçª—å£
            current_window = current_timestamp // skip_interval
            
            # åªæœ‰è¿›å…¥æ–°çª—å£æ—¶æ‰å¤„ç†
            process_ais_vis_fus = (current_window != last_processed_window)
            
            if process_ais_vis_fus:
                # print(f"process_ais_vis_fus at timestamp {current_timestamp}, worker {cam_idx} processing task, pid={os.getpid()}")
                # 1. AIS
                AIS_vis, AIS_cur = aispro.process(ais_batch, camera_pos_para, current_timestamp, camera_type)
                # 2. VIS
                Vis_tra, Vis_cur = vispro.feedCap(cv_image, AIS_vis, bin_inf, current_timestamp)
                # 3. FUS
                Fus_tra, updated_bin = fuspro.fusion(AIS_vis, AIS_cur, Vis_tra, Vis_cur, current_timestamp)
                # 4. DRAW
                im, Visiable_Tra = dra.draw_match_traj(cv_image, AIS_vis, AIS_cur, Vis_tra, Vis_cur, Fus_tra, timestamp=current_timestamp)
                # æ›´æ–°é…å¯¹å…³ç³»
                Last_Visiable_Tra = Visiable_Tra
                # æ›´æ–°çª—å£æ ‡è®°
                last_processed_window = current_window
            else:
                # print(f"no process_ais_vis_fus at timestamp {current_timestamp}, worker {cam_idx} processing task, pid={os.getpid()}")
                im = dra.draw_no_match_traj(cv_image)
                Visiable_Tra = Last_Visiable_Tra
            
            end_time = time.time()
            time_cost = end_time - start_time
            result = {
                "cam_idx": cam_idx, 
                "image": im, 
                "timestamp": current_timestamp, 
                "Visiable_Tra": Visiable_Tra,
                # "fus_trajectory": pd.DataFrame(),
                "time_cost": time_cost
            }
            try:
                output_queue.put_nowait(result)
            except:
                print(f"[PID {os.getpid()}] output queue full for cam{cam_idx}, drop result")
        except Exception as e:
            error_msg = f"!!! worker cam{cam_idx} error: {e}\n{traceback.format_exc()}"
            print(error_msg)
            try:
                output_queue.put_nowait({"cam_idx": cam_idx, "error": error_msg})
            except:
                pass
# ------------------------------------------------------





class AisVisNode(Node):
    def __init__(self,):
        super().__init__('ais_vis_node')

        # å£°æ˜é…ç½®æ–‡ä»¶å‚æ•°
        self.declare_parameter('config_file', '')
        config_file = self.get_parameter('config_file').get_parameter_value().string_value
        
        # å¦‚æœæœªæŒ‡å®šé…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„
        if not config_file:
            try:
                config_file = ConfigLoader.find_config_file('marnav_vis', 'track_realtime_config.yaml')
                self.get_logger().info(f"æœªæŒ‡å®šé…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„: {config_file}")
            except Exception as e:
                self.get_logger().error(f"æŸ¥æ‰¾é»˜è®¤é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
                raise
        
        # åŠ è½½é…ç½®
        try:
            config_loader = ConfigLoader(config_file)
            camera_config = config_loader.get_camera_config()
            ais_config = config_loader.get_ais_config()
            gnss_config = config_loader.get_gnss_config()
            deepsorvf_config = config_loader.get_deepsorvf_config()
        except Exception as e:
            self.get_logger().fatal(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            raise
        
        # ä»é…ç½®ä¸­è¯»å–å‚æ•°
        self.angle_between_cameras = camera_config.get('angle_between_cameras')
        self.im_shape = tuple(camera_config.get('width_height', [2560, 1440]))
        self.camera_parameters = camera_config.get('camera_parameters', [])
        self.camera_topics = [cam['topic_name'] for cam in self.camera_parameters]
        self.camera_matrixs = [cam['camera_matrix'] for cam in self.camera_parameters]  
        self.camera_type = deepsorvf_config.get('camera_type', "normal")
        if self.camera_type == 'fisheye':
            self.distortion_coefficients = [cam['distortion_coefficients'] for cam in self.camera_parameters]
        else:
            self.distortion_coefficients = None # æ™®é€šç›¸æœºä¸éœ€è¦ç•¸å˜ç³»æ•°
        # æ„å»ºç›¸æœºtopicåˆ°æ ‡å‡†åç§°çš„æ˜ å°„ï¼ˆä¸C++æ‹¼æ¥èŠ‚ç‚¹ä¿æŒä¸€è‡´ï¼‰
        self.camera_name_mapping = {}
        for cam in self.camera_parameters:
            self.camera_name_mapping[cam['topic_name']] = cam['camera_name']
        
        self.ais_batch_pub_topic = ais_config.get('ais_batch_pub_topic', '/ais_batch_topic')
        self.fus_trajectory_topic = deepsorvf_config.get('fus_trajectory_topic', '/fus_trajectory_topic')
        self.gnss_pub_topic = gnss_config.get('gnss_pub_topic', '/gnss_pub_topic')
        
        self.input_fps = deepsorvf_config.get('input_fps', 20)
        self.t = int(1000 / self.input_fps)
        self.output_fps = deepsorvf_config.get('output_fps', 10)
        
        self.anti = deepsorvf_config.get('anti', 1)
        self.anti_rate = deepsorvf_config.get('anti_rate', 0)
        self.sync_queue_size = deepsorvf_config.get('sync_queue_size', 10)
        self.sync_slop = deepsorvf_config.get('sync_slop', 0.1)
        self.skip_interval = deepsorvf_config.get('skip_interval', 1000)
        self.camera_type = deepsorvf_config.get('camera_type', "normal")
        self.yolo_type = deepsorvf_config.get('yolo_type', "yolo11m")
        
        # æ‰“å°é…ç½®ä¿¡æ¯
        self.get_logger().info("="*60)
        self.get_logger().info("ğŸš¢ èˆ¹åªè·Ÿè¸ªèŠ‚ç‚¹é…ç½®")
        self.get_logger().info("="*60)
        self.get_logger().info(f"é…ç½®æ–‡ä»¶: {config_file}")
        self.get_logger().info(f"å›¾åƒå°ºå¯¸: {self.im_shape[0]}x{self.im_shape[1]}")
        self.get_logger().info(f"ç›¸æœºæ•°é‡: {len(self.camera_topics)}")
        for i, (topic, name) in enumerate(self.camera_name_mapping.items()):
            self.get_logger().info(f"  ç›¸æœºæ˜ å°„å…³ç³»{i}: {topic} -> {name}")
        self.get_logger().info(f"è¾“å…¥/è¾“å‡ºFPS: {self.input_fps}/{self.output_fps}")
        self.get_logger().info(f"å¤„ç†é—´éš”: {self.skip_interval} ms")
        self.get_logger().info(f"åŒæ­¥é˜Ÿåˆ—: {self.sync_queue_size}, åŒæ­¥è¯¯å·®: {self.sync_slop}s")
        self.get_logger().info(f"ç›¸æœºç±»å‹: {self.camera_type}")
        self.get_logger().info(f"YOLOæ¨¡å‹ç±»å‹: {self.yolo_type}")
        self.get_logger().info("="*60)

        self.bridge = CvBridge()
        self.aisbatch_cache = pd.DataFrame(columns=['ID', 'mmsi', 'timestamp', 'lat', 'lon', 'sog', 'cog', 'heading', 'status', 'type'])
        self.aisbatch_time = None
        # self.gnss_cache = None
        self.camera_pos_para = {}
        self.max_dis = min(self.im_shape) // 2
        self.name = 'ROS version 2 demo'
        
        # å­˜å‚¨GNSSé…ç½®ï¼ˆä»é…ç½®æ–‡ä»¶è¯»å–ï¼Œç”¨äºåˆå§‹åŒ–ï¼‰
        self.gnss_config = gnss_config

        self.num_cameras = len(self.camera_topics)
        self.bin_inf = [pd.DataFrame(columns=['ID', 'mmsi', 'timestamp', 'match']) for _ in range(self.num_cameras)]
        self.fus_trajectory = [pd.DataFrame() for _ in range(self.num_cameras)]
        # åˆå§‹åŒ–æ¯ä¸ªç›¸æœºçš„æœ€æ–°å¤„ç†å›¾åƒä¸ºç©ºç™½å›¾åƒ
        blank_image = np.zeros((self.im_shape[1], self.im_shape[0], 3), dtype=np.uint8)
        self.latest_processed_images = {
            self.camera_topics[i]: blank_image.copy() for i in range(self.num_cameras)
        }
        # ============ å¤šè¿›ç¨‹æ± æ ¸å¿ƒéƒ¨åˆ†ï¼ˆæ¯æ‘„åƒå¤´ä¸€ä¸ªè¿›ç¨‹ï¼‰ ===============
        self.mp_input_queues = [Queue(maxsize=10) for _ in range(self.num_cameras)]
        self.mp_output_queues = [Queue(maxsize=10) for _ in range(self.num_cameras)]
        self.workers = [
            Process(
                target=multi_proc_worker,
                args=(self.mp_input_queues[i], self.mp_output_queues[i], self.im_shape, self.t, self.max_dis, self.skip_interval, self.camera_type, self.yolo_type)
            )
            for i in range(self.num_cameras)
        ]
        for p in self.workers:
            p.daemon = True
            p.start()
        # ===========================================
        self.stitch_image_queue = []
        self.latest_stitch = None
        self.print_logger = False

        # åˆ›å»ºç”¨äºæ˜¾ç¤ºçš„å›¾åƒçª—å£
        cv2.namedWindow(self.name, cv2.WINDOW_NORMAL)

        qos_profile=QoSProfile(
            reliability=QoSReliabilityPolicy.BEST_EFFORT,
            history=QoSHistoryPolicy.KEEP_LAST,
            depth=3
        )

        # è®¢é˜…ç›¸æœºå›¾åƒå’Œå¯¹åº”çš„åŒæ­¥å™¨
        self.camera_subscribers = []
        for topic in self.camera_topics:
            sub = Subscriber(self, Image, topic, qos_profile=qos_profile)
            self.camera_subscribers.append(sub)
        self.ts = ApproximateTimeSynchronizer(
            self.camera_subscribers,
            queue_size=self.sync_queue_size,
            slop=self.sync_slop
        )
        self.ts.registerCallback(self.synchronized_camera_callback)

        # è®¢é˜…AISå’ŒGNSSæ•°æ®
        self.aisbatch_subscriber = self.create_subscription(
            AisBatch,
            self.ais_batch_pub_topic,
            self.aisbatch_callback,
            10
        )
        self.gnss_subscriber = self.create_subscription(
            Gnss,
            self.gnss_pub_topic,
            self.gnss_callback,
            10
        )
        # å®šæ—¶åˆ·æ–°æ˜¾ç¤ºçª—å£
        self.window_timer = self.create_timer(1/self.output_fps, self.refresh_window_callback)

        # å®šæ—¶å‘å¤–å‘å¸ƒè½¨è¿¹ä¿¡æ¯çš„å‘å¸ƒå™¨
        self.fus_trajectory_publisher = self.create_publisher(VisiableTraBatch, self.fus_trajectory_topic, qos_profile)
        
        # å®šæ—¶å‘å¸ƒè½¨è¿¹ï¼ˆ1ç§’ä¸€æ¬¡ï¼‰
        self.trajectory_publish_timer = self.create_timer(1.0, self.publish_trajectory_callback)


    # =================== å›è°ƒå‡½æ•° ====================
    def synchronized_camera_callback(self, *msgs):
        # æ”¶é›†è¾“å…¥æ•°æ®å°åŒ…æ¨é€è¿›å¤šè¿›ç¨‹é˜Ÿåˆ—
        # æ£€æŸ¥ç›¸æœºä½ç½®å‚æ•°æ˜¯å¦å·²åˆå§‹åŒ–ï¼ˆå¿…éœ€ï¼‰
        if not self.camera_pos_para:
            self.get_logger().warning("ç­‰å¾…GNSSæ•°æ®æ›´æ–°ç›¸æœºä½ç½®å‚æ•°ï¼Œæš‚ä¸å¤„ç†å›¾åƒå¸§", throttle_duration_sec=5.0)
            return
        
        # æ£€æŸ¥AISæ•°æ®ï¼ˆéå¿…éœ€ï¼Œä»…è­¦å‘Šï¼‰
        if self.aisbatch_cache.empty:
            self.get_logger().warning("æœªæ”¶åˆ°AISæ•°æ®ï¼Œå°†ä»…ä½¿ç”¨è§†è§‰è·Ÿè¸ªæ¨¡å¼", throttle_duration_sec=5.0)
        # self.get_logger().info(f"æ”¶åˆ°åŒæ­¥ç›¸æœºå¸§ï¼Œå…±{len(msgs)}å¸§")
        cv_images = [self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8') for msg in msgs]
        current_timestamp = msgs[0].header.stamp.sec * 1000 + msgs[0].header.stamp.nanosec // 1000000
        for cam_idx in range(self.num_cameras):
            if cam_idx >= len(cv_images):
                continue

             # æ£€æŸ¥ camera_pos_para å’Œ bin_inf æ˜¯å¦å®Œæ•´
            camera_ok = cam_idx in self.camera_pos_para and isinstance(self.camera_pos_para[cam_idx], dict)
            bin_ok = len(self.bin_inf) > cam_idx and isinstance(self.bin_inf[cam_idx], pd.DataFrame)

            if not camera_ok:
                self.get_logger().warning(f"camera_pos_para[{cam_idx}] ç¼ºå¤±æˆ–ç±»å‹é”™è¯¯ï¼Œå†…å®¹ï¼š{self.camera_pos_para.get(cam_idx, None)}ï¼Œè·³è¿‡è¯¥å¸§")
                continue
            if not bin_ok:
                self.get_logger().warning(f"bin_inf[{cam_idx}] ç¼ºå¤±æˆ–ç±»å‹é”™è¯¯ï¼Œå†…å®¹ï¼š{self.bin_inf[cam_idx] if len(self.bin_inf) > cam_idx else 'None'}ï¼Œè·³è¿‡è¯¥å¸§")
                continue


            # æäº¤ä»»åŠ¡ç»™å¯¹åº”æ‘„åƒå¤´çš„è¿›ç¨‹
            try:
                self.mp_input_queues[cam_idx].put_nowait({
                    "cam_idx": cam_idx,
                    "cv_image": cv_images[cam_idx],
                    "current_timestamp": current_timestamp,
                    "ais_batch": self.aisbatch_cache,
                    "camera_pos_para": self.camera_pos_para[cam_idx],
                    "bin_inf": self.bin_inf[cam_idx] if len(self.bin_inf) > cam_idx else pd.DataFrame(),
                })
                # self.get_logger().info(f"æäº¤ cam{cam_idx} ä¸€å¸§åˆ°å¤šè¿›ç¨‹é˜Ÿåˆ—")
            except Exception as e:
                self.get_logger().debug(f"å¤šè¿›ç¨‹è¾“å…¥é˜Ÿåˆ—æ»¡ï¼Œä¸¢å¼ƒ cam{cam_idx} å½“å‰å¸§: {e}")
                
    def aisbatch_callback(self, msg: AisBatch):
        # self.get_logger().info(f"æ”¶åˆ°AISæ•°æ®")  # æ·»åŠ æ­¤è¡Œ
        data_list = []
        for ais in msg.ais_list:
            timestamp_ms = ais.timestamp.sec * 1000 + ais.timestamp.nanosec // 1000000
            data_list.append({
                'mmsi': ais.mmsi,
                'lon': ais.lon,
                'lat': ais.lat,
                'speed': ais.speed,
                'course': ais.course,
                'heading': ais.heading,
                'type': ais.type,
                'timestamp': timestamp_ms
            })
        aisbatch_df = pd.DataFrame(data_list, columns=['mmsi','lon','lat','speed','course','heading','type','timestamp'])
        self.aisbatch_cache = aisbatch_df
        if len(self.aisbatch_cache) > 100:
            self.aisbatch_cache = self.aisbatch_cache.tail(100).copy()

    def gnss_callback(self, msg: Gnss):
        """GNSSå›è°ƒå‡½æ•°ï¼šæ›´æ–°ç›¸æœºä½ç½®å‚æ•°"""
        self.gnss_cache = msg
        
        # æ›´æ–°ç›¸æœºä½ç½®ä¿¡æ¯ï¼Œä»¥ä¸­é—´ç›¸æœºä¸ºæ­£å‰æ–¹
        # å·¦å³ç›¸æœºçš„æ°´å¹³æœå‘åˆ†åˆ«è°ƒæ•´-60å’Œ+60åº¦
        for idx, topic in enumerate(self.camera_topics):
            # è®¡ç®—æ°´å¹³æœå‘ï¼ˆä¸­é—´ç›¸æœºä¸å˜ï¼Œå·¦å³ç›¸æœºè°ƒæ•´Â±Nåº¦,Nä¸ºç›¸æœºä¹‹é—´çš„å¤¹è§’ï¼‰
            horizontal_orientation = (msg.horizontal_orientation + (idx - 1) * self.angle_between_cameras) % 360
            # å¼€å§‹æ··åˆèµ‹å€¼
            if self.camera_type == 'fisheye':
                self.camera_pos_para[idx] = {
                    "longitude": msg.longitude,
                    "latitude": msg.latitude,
                    "horizontal_orientation": horizontal_orientation,  # æ¯ä¸ªç›¸æœºçš„æ°´å¹³æœå‘ç”±yamlæ–‡ä»¶é…ç½®
                    "vertical_orientation": msg.vertical_orientation,
                    "camera_height": msg.camera_height,

                    'fov_hor': self.camera_matrixs[idx]['fov_hor'], # æ•°æ®é›†æ¨¡å¼ä¸‹è¿™å‚æ•°æ˜¯å›ºå®šçš„
                    'fov_ver': self.camera_matrixs[idx]['fov_ver'],
                    'fx': self.camera_matrixs[idx]['fx'],
                    'fy': self.camera_matrixs[idx]['fy'],
                    'u0': self.camera_matrixs[idx]['u0'],
                    'v0': self.camera_matrixs[idx]['v0'],

                    'k1': self.distortion_coefficients[idx]['k1'],
                    'k2': self.distortion_coefficients[idx]['k2'],
                    'k3': self.distortion_coefficients[idx]['k3'],
                    'k4': self.distortion_coefficients[idx]['k4'],
                }
            elif self.camera_type == 'normal':
                self.camera_pos_para[idx] = {
                    "longitude": msg.longitude,
                    "latitude": msg.latitude,
                    "horizontal_orientation": horizontal_orientation,  # æ¯ä¸ªç›¸æœºçš„æ°´å¹³æœå‘ç”±yamlæ–‡ä»¶é…ç½®
                    "vertical_orientation": msg.vertical_orientation,
                    "camera_height": msg.camera_height,

                    'fov_hor': self.camera_matrixs[idx]['fov_hor'], # æ•°æ®é›†æ¨¡å¼ä¸‹è¿™å‚æ•°æ˜¯å›ºå®šçš„
                    'fov_ver': self.camera_matrixs[idx]['fov_ver'],
                    'fx': self.camera_matrixs[idx]['fx'],
                    'fy': self.camera_matrixs[idx]['fy'],
                    'u0': self.camera_matrixs[idx]['u0'],
                    'v0': self.camera_matrixs[idx]['v0'],
                }
            

    def refresh_window_callback(self):
        # å›æ”¶å¤šè¿›ç¨‹è¾“å‡ºç»“æœ
        for cam_idx in range(self.num_cameras):
            try:
                while True:
                    result = self.mp_output_queues[cam_idx].get_nowait()
                    if "error" in result:
                        self.get_logger().error(f"å­è¿›ç¨‹Camera {result['cam_idx']}å‡ºé”™: {result['error']}")
                        continue
                    cam_idx = result["cam_idx"]
                    self.fus_trajectory[cam_idx] = result["Visiable_Tra"]
                    self.fus_trajectory[cam_idx]['timestamp'] = result["timestamp"]
                    # time_cost = result.get("time_cost", 0)
                    # if time_cost is not None:
                    #     self.get_logger().info(f"Camera {cam_idx}  Time cost: {time_cost} seconds")
                    self.latest_processed_images[self.camera_topics[cam_idx]] = result["image"]
            except Exception:
                pass  # å½“å‰ç›¸æœºé˜Ÿåˆ—ç©ºï¼Œç»§ç»­ä¸‹ä¸€ä¸ª
        
        # æ£€æŸ¥è¿›ç¨‹å¥åº·çŠ¶æ€
        for i, p in enumerate(self.workers):
            if not p.is_alive():
                self.get_logger().error(f"Worker {i} (PID {p.pid}) å·²æ­»äº¡ï¼")

        # æ‹¼æ¥å›¾åƒå¹¶æ˜¾ç¤º
        current_images = self.latest_processed_images.copy()
        
        # éªŒè¯æ‰€æœ‰å›¾åƒæ˜¯å¦å­˜åœ¨ä¸”å°ºå¯¸ä¸€è‡´ï¼ˆé¿å…hconcaté”™è¯¯ï¼‰
        images_to_concat = []
        target_shape = None
        all_valid = True
        
        for cam_name in self.camera_topics:
            img = current_images.get(cam_name)
            if img is None:
                self.get_logger().debug(f"ç›¸æœº {cam_name} å›¾åƒä¸ºNoneï¼Œè·³è¿‡æœ¬æ¬¡æ‹¼æ¥")
                all_valid = False
                break
            
            # æ£€æŸ¥å›¾åƒå°ºå¯¸å’Œç±»å‹
            if target_shape is None:
                target_shape = img.shape
            elif img.shape != target_shape:
                self.get_logger().warning(
                    f"ç›¸æœº {cam_name} å›¾åƒå°ºå¯¸ä¸åŒ¹é…: {img.shape} != {target_shape}ï¼Œ"
                    f"å°†è°ƒæ•´ä¸ºç›®æ ‡å°ºå¯¸åæ‹¼æ¥"
                )
                # è°ƒæ•´å›¾åƒå°ºå¯¸ä»¥åŒ¹é…ç›®æ ‡
                img = cv2.resize(img, (target_shape[1], target_shape[0]))
            
            images_to_concat.append(img)
        
        # åªæœ‰å½“æ‰€æœ‰å›¾åƒéƒ½æœ‰æ•ˆæ—¶æ‰è¿›è¡Œæ‹¼æ¥
        if all_valid and len(images_to_concat) == len(self.camera_topics):
            try:
                stitched_image = cv2.hconcat(images_to_concat)
                cv2.imshow(self.name, stitched_image)
                cv2.waitKey(1)
            except cv2.error as e:
                self.get_logger().error(f"å›¾åƒæ‹¼æ¥å¤±è´¥: {e}")
        else:
            self.get_logger().debug("ç­‰å¾…æ‰€æœ‰ç›¸æœºå›¾åƒå°±ç»ª...")

    def publish_trajectory_callback(self):
        """å®šæ—¶å‘å¸ƒèåˆè½¨è¿¹ï¼ˆ1ç§’ä¸€æ¬¡ï¼‰"""
        msg_batch = VisiableTraBatch()
        msg_batch.visiable_tra_list = []
        
        for cam_idx in range(self.num_cameras):
            if self.fus_trajectory[cam_idx].empty:
                continue  # è·³è¿‡ç©ºçš„è½¨è¿¹æ•°æ®
            
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªè½¨è¿¹çš„æ—¶é—´æˆ³ä½œä¸ºbatchçš„æ—¶é—´æˆ³
            if not self.fus_trajectory[cam_idx].empty:
                first_tra = self.fus_trajectory[cam_idx].iloc[0]
                batch_timestamp_ms = int(first_tra.get('timestamp', 0))
                msg_batch.timestamp.sec = batch_timestamp_ms // 1000
                msg_batch.timestamp.nanosec = (batch_timestamp_ms % 1000) * 1000000

            for idx, tra in self.fus_trajectory[cam_idx].iterrows():
                try:
                    msg = VisiableTra()
                    # ä½¿ç”¨æ˜ å°„åçš„ç›¸æœºåç§°ï¼ˆä¸C++æ‹¼æ¥èŠ‚ç‚¹ä¿æŒä¸€è‡´ï¼‰
                    topic_name = self.camera_topics[cam_idx]
                    # =================================================== DEBUG ===================================================
                    msg.camera_name = self.camera_name_mapping.get(topic_name, topic_name) # ç¬¬ä¸€ä¸ªtopic_nameä½œä¸ºé”®åï¼Œç¬¬äºŒä¸ªæ˜¯è‹¥æ²¡æœ‰å¯¹åº”çš„é”®å€¼å¯¹ï¼Œåˆ™è¿”å›åŸå€¼
                    # =================================================== DEBUG ===================================================
                    # å°†æ¯«ç§’æ—¶é—´æˆ³è½¬æ¢ä¸º ROS Time (sec + nanosec)
                    timestamp_ms = int(tra.get('timestamp', 0))
                    msg.timestamp.sec = timestamp_ms // 1000
                    msg.timestamp.nanosec = (timestamp_ms % 1000) * 1000000
                    
                    # AISç›¸å…³å­—æ®µï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨é»˜è®¤å€¼
                    msg.ais = 0 if pd.isna(tra.get('ais')) or tra.get('ais') is None else int(tra['ais'])
                    
                    # èˆ¹åªç±»å‹ï¼šä»èåˆç»“æœä¸­è·å–class_name
                    class_name_value = tra.get('class_name')

                    if pd.isna(class_name_value) or class_name_value is None or class_name_value == '':
                        msg.ship_type = 'vessel'  # é»˜è®¤ç±»å‹
                    else:
                        msg.ship_type = str(class_name_value)
                    # mmsi å¿…é¡»æ˜¯æ— ç¬¦å·æ•´æ•° [0, 4294967295]ï¼Œè´Ÿæ•°è½¬ä¸º0
                    mmsi_value = tra.get('mmsi', 0)
                    if pd.isna(mmsi_value) or mmsi_value < 0:
                        msg.mmsi = 0
                    else:
                        msg.mmsi = int(mmsi_value)
                    self.get_logger().info(f"æœ€ç»ˆ msg.mmsi: {msg.mmsi}, msg.ship_type: {msg.ship_type}")

                    # é€Ÿåº¦å’Œèˆªå‘ï¼Œè´Ÿæ•°è½¬ä¸º0.0
                    sog_value = tra.get('sog', 0.0)
                    msg.sog = float(sog_value) if not pd.isna(sog_value) and sog_value >= 0 else 0.0
                    cog_value = tra.get('cog', 0.0)
                    msg.cog = float(cog_value) if not pd.isna(cog_value) and cog_value >= 0 else 0.0
                    
                    # ç»çº¬åº¦ï¼Œè´Ÿæ•°å¯èƒ½æ˜¯æœ‰æ•ˆçš„ï¼ˆå—çº¬ã€è¥¿ç»ï¼‰ï¼Œåªæ£€æŸ¥NaN
                    msg.lat = float(tra.get('lat', 0.0)) if not pd.isna(tra.get('lat')) else 0.0
                    msg.lon = float(tra.get('lon', 0.0)) if not pd.isna(tra.get('lon')) else 0.0
                    
                    # è§†è§‰æ£€æµ‹æ¡†åæ ‡ï¼ˆå¿…éœ€å­—æ®µï¼‰
                    msg.box_x1 = float(tra.get('box_x1', 0.0))
                    msg.box_y1 = float(tra.get('box_y1', 0.0))
                    msg.box_x2 = float(tra.get('box_x2', 0.0))
                    msg.box_y2 = float(tra.get('box_y2', 0.0))
                    
                    msg_batch.visiable_tra_list.append(msg)
                except Exception as e:
                    self.get_logger().warning(f"å‘å¸ƒè½¨è¿¹æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
        
        # åªæœ‰åœ¨æœ‰æ•°æ®æ—¶æ‰å‘å¸ƒ
        if len(msg_batch.visiable_tra_list) > 0:
            self.fus_trajectory_publisher.publish(msg_batch)
            # self.get_logger().info(f"å‘å¸ƒäº† {len(msg_batch.visiable_tra_list)} ä¸ªè½¨è¿¹")

    def destroy_node(self):
        # å…³é—­æ‰€æœ‰å¤šè¿›ç¨‹
        for q in self.mp_input_queues:
            q.put(None)
        for p in self.workers:
            p.join(timeout=5)
        super().destroy_node()

    def save_to_local(self, AIS_vis, AIS_cur, Vis_tra, Vis_tra_cur, Fus_tra, current_timestamp):
        if current_timestamp % 1000 < self.t:
            result_name_vis = f'result/AIS_vis/AIS_vis_{current_timestamp}.csv'
            result_name_cur = f'result/AIS_cur/AIS_cur_{current_timestamp}.csv'
            result_name_tra_cur = f'result/Vis_tra_cur/Vis_tra_cur_{current_timestamp}.csv'
            result_name_tra = f'result/Vis_tra/Vis_tra_{current_timestamp}.csv'
            result_name_fus_tra = f'result/Fus_tra/Fus_tra_{current_timestamp}.csv'
            AIS_vis.to_csv(result_name_vis, index=False)
            AIS_cur.to_csv(result_name_cur, index=False)
            Vis_tra.to_csv(result_name_tra, index=False)
            Vis_tra_cur.to_csv(result_name_tra_cur, index=False)
            Fus_tra.to_csv(result_name_fus_tra, index=False)

def main(args=None):
    try:
        set_start_method('spawn')
    except RuntimeError:
        pass
    rclpy.init(args=args)

    node = AisVisNode()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        node.get_logger().info("Node interrupted by user")
    finally:
        node.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()
