// åŸºäºROS 2çš„DeepSORVFè·Ÿè¸ªèŠ‚ç‚¹ï¼Œå®ç°å¤šç›¸æœºå›¾åƒçš„AIS+VIS+FUSå¤„ç†
// ä¹Ÿå°±æ˜¯ä¸pythonç‰ˆæœ¬çš„DeepSORVFè·Ÿè¸ªèŠ‚ç‚¹åŠŸèƒ½ä¸€è‡´
// ä½†æ˜¯ä½¿ç”¨C++å®ç°ï¼Œè€Œä¸æ˜¯Python
// ä½¿ç”¨ROS 2çš„ç‰¹æ€§ï¼Œå®ç°å¤šç›¸æœºå›¾åƒçš„åŒæ­¥å¤„ç†
// æ³¨æ„ï¼šC++ç‰ˆæœ¬ä½¿ç”¨å¤šçº¿ç¨‹è€Œä¸æ˜¯å¤šè¿›ç¨‹ï¼ˆå› ä¸ºC++æ²¡æœ‰GILé™åˆ¶ï¼‰ï¼Œæ€§èƒ½è¶³å¤Ÿå¥½
// ä¸Pythonç‰ˆæœ¬çš„å¤šè¿›ç¨‹åŠŸèƒ½ç­‰ä»·ï¼Œä½†å®ç°æ›´ç®€å•é«˜æ•ˆ

#include <rclcpp/rclcpp.hpp>
#include <sensor_msgs/msg/image.hpp>
#include <marnav_interfaces/msg/ais_batch.hpp>
#include <marnav_interfaces/msg/gnss.hpp>
#include <marnav_interfaces/msg/visiable_tra_batch.hpp>
#include <marnav_interfaces/msg/visiable_tra.hpp>

#include <cv_bridge/cv_bridge.h>
#include <opencv2/opencv.hpp>

#include <message_filters/subscriber.h>
#include <message_filters/synchronizer.h>
#include <message_filters/sync_policies/approximate_time.h>

#include <yaml-cpp/yaml.h>
#include <ament_index_cpp/get_package_share_directory.hpp>

#include <memory>
#include <vector>
#include <string>
#include <thread>
#include <mutex>
#include <queue>
#include <atomic>
#include <condition_variable>
#include <chrono>
#include <map>
#include <deque>
#include <algorithm>
#include <cmath>

#include "marnav_vis_cpp/AIS_utils.h"

using namespace std::chrono_literals;

// ç›¸æœºé…ç½®ç»“æ„
struct CameraConfig {
    std::string camera_name;
    std::string topic_name;
    int camera_index;
    // ç›¸æœºå†…å‚
    double fov_hor;
    double fov_ver;
    double fx;
    double fy;
    double u0;
    double v0;
    // ç•¸å˜ç³»æ•°ï¼ˆé±¼çœ¼ç›¸æœºï¼‰
    double k1 = 0.0;
    double k2 = 0.0;
    double k3 = 0.0;
    double k4 = 0.0;
};

// æ³¨æ„ï¼šCameraPosParaå’ŒAISDataåœ¨AIS_utils.hä¸­å®šä¹‰

// è½¨è¿¹æ•°æ®ç»“æ„ï¼ˆç®€åŒ–çš„Visiable_Traï¼‰
struct VisiableTraData {
    int cam_idx;
    int64_t timestamp_ms;
    uint8_t ais;  // 0æˆ–1
    uint32_t mmsi;
    std::string ship_type;
    float sog;
    float cog;
    float lat;
    float lon;
    float box_x1;
    float box_y1;
    float box_x2;
    float box_y2;
};

// ä»»åŠ¡æ•°æ®ç»“æ„ï¼ˆå‘é€ç»™workerï¼‰
struct ProcessingTask {
    int cam_idx;
    cv::Mat cv_image;
    int64_t current_timestamp_ms;
    std::vector<AISData> ais_batch;
    CameraPosPara camera_pos_para;
    // bin_inf å¯ä»¥åç»­æ·»åŠ 
};

// ç»“æœæ•°æ®ç»“æ„ï¼ˆä»workeræ¥æ”¶ï¼‰
struct ProcessingResult {
    int cam_idx;
    cv::Mat processed_image;
    int64_t timestamp_ms;
    std::vector<VisiableTraData> visiable_tra_list;
    double time_cost;
};

class DeepSORVFNode : public rclcpp::Node
{
public:
    DeepSORVFNode();
    ~DeepSORVFNode();

private:
    // é…ç½®åŠ è½½
    bool loadConfig(const std::string& config_file);
    
    // å›è°ƒå‡½æ•°
    void synchronized_camera_callback(const sensor_msgs::msg::Image::ConstSharedPtr& img1,
                                     const sensor_msgs::msg::Image::ConstSharedPtr& img2,
                                     const sensor_msgs::msg::Image::ConstSharedPtr& img3);
    void aisbatch_callback(const marnav_interfaces::msg::AisBatch::SharedPtr msg);
    void gnss_callback(const marnav_interfaces::msg::Gnss::SharedPtr msg);
    void refresh_window_callback();
    void publish_trajectory_callback();
    
    // Workerçº¿ç¨‹å‡½æ•°ï¼ˆæ¯ä¸ªç›¸æœºä¸€ä¸ªçº¿ç¨‹ï¼Œç­‰ä»·äºPythonçš„å¤šè¿›ç¨‹workerï¼‰
    void worker_thread(int cam_idx);
    
    // è¾…åŠ©å‡½æ•°
    int64_t timestamp_to_ms(const builtin_interfaces::msg::Time& stamp);
    std::vector<AISData> convert_ais_batch(const marnav_interfaces::msg::AisBatch::SharedPtr& msg);
    
    // é…ç½®å‚æ•°
    std::vector<CameraConfig> camera_configs_;
    std::map<std::string, std::string> camera_name_mapping_; // topic -> camera_name
    std::pair<int, int> im_shape_; // width, height
    double angle_between_cameras_;
    std::string camera_type_; // "normal" or "fisheye"
    
    std::string ais_batch_topic_;
    std::string gnss_topic_;
    std::string fus_trajectory_topic_;
    
    int input_fps_;
    int output_fps_;
    int t_ms_; // æ—¶é—´é—´éš”ï¼ˆæ¯«ç§’ï¼‰
    int sync_queue_size_;
    double sync_slop_;
    int skip_interval_ms_;
    int max_dis_;
    
    // ROS 2ç›¸å…³
    std::vector<std::shared_ptr<message_filters::Subscriber<sensor_msgs::msg::Image>>> camera_subscribers_;
    std::shared_ptr<message_filters::Synchronizer<message_filters::sync_policies::ApproximateTime<
        sensor_msgs::msg::Image, sensor_msgs::msg::Image, sensor_msgs::msg::Image>>> sync_;
    
    rclcpp::Subscription<marnav_interfaces::msg::AisBatch>::SharedPtr aisbatch_subscriber_;
    rclcpp::Subscription<marnav_interfaces::msg::Gnss>::SharedPtr gnss_subscriber_;
    rclcpp::Publisher<marnav_interfaces::msg::VisiableTraBatch>::SharedPtr fus_trajectory_publisher_;
    
    rclcpp::TimerBase::SharedPtr window_timer_;
    rclcpp::TimerBase::SharedPtr trajectory_publish_timer_;
    
    // æ•°æ®ç¼“å­˜
    std::vector<AISData> aisbatch_cache_;
    std::mutex aisbatch_mutex_;
    
    std::map<int, CameraPosPara> camera_pos_para_;
    std::mutex camera_pos_para_mutex_;
    
    // å¤šçº¿ç¨‹å¤„ç†ï¼ˆæ¯ä¸ªç›¸æœºä¸€ä¸ªçº¿ç¨‹ï¼Œç­‰ä»·äºPythonçš„å¤šè¿›ç¨‹ï¼‰
    std::vector<std::thread> worker_threads_;
    std::vector<std::queue<ProcessingTask>> input_queues_;
    std::vector<std::queue<ProcessingResult>> output_queues_;
    std::vector<std::shared_ptr<std::mutex>> input_queue_mutexes_;
    std::vector<std::shared_ptr<std::mutex>> output_queue_mutexes_;
    std::vector<std::shared_ptr<std::condition_variable>> input_queue_cvs_;
    std::atomic<bool> running_{true};
    
    // å¤„ç†ç»“æœç¼“å­˜
    std::map<std::string, cv::Mat> latest_processed_images_;
    std::mutex processed_images_mutex_;
    
    // èåˆè½¨è¿¹ç¼“å­˜ï¼ˆæ¯ä¸ªç›¸æœºä¸€ä¸ªï¼‰
    std::vector<std::vector<VisiableTraData>> fus_trajectory_;
    std::mutex fus_trajectory_mutex_;
    
    // æ˜¾ç¤ºçª—å£åç§°
    std::string window_name_ = "ROS version 2 demo";
    
    // æœ€å¤§é˜Ÿåˆ—å¤§å°
    static constexpr size_t MAX_QUEUE_SIZE = 10;
};

DeepSORVFNode::DeepSORVFNode()
    : Node("ais_vis_node")
{
    // å£°æ˜å¹¶è·å–é…ç½®æ–‡ä»¶å‚æ•°
    this->declare_parameter<std::string>("config_file", "");
    std::string config_file = this->get_parameter("config_file").as_string();
    
    // å¦‚æœæœªæŒ‡å®šé…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„
    if (config_file.empty()) {
        try {
            std::string package_share_dir = ament_index_cpp::get_package_share_directory("marnav_vis");
            config_file = package_share_dir + "/config/track_realtime_config.yaml";
            RCLCPP_INFO(this->get_logger(), "æœªæŒ‡å®šé…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„: %s", config_file.c_str());
        } catch (const std::exception& e) {
            RCLCPP_ERROR(this->get_logger(), "æŸ¥æ‰¾é»˜è®¤é…ç½®æ–‡ä»¶å¤±è´¥: %s", e.what());
            throw;
        }
    }
    
    // åŠ è½½é…ç½®
    if (!loadConfig(config_file)) {
        RCLCPP_FATAL(this->get_logger(), "åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥");
        throw std::runtime_error("é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥");
    }
    
    // æ‰“å°é…ç½®ä¿¡æ¯
    RCLCPP_INFO(this->get_logger(), "============================================================");
    RCLCPP_INFO(this->get_logger(), "ğŸš¢ èˆ¹åªè·Ÿè¸ªèŠ‚ç‚¹é…ç½®");
    RCLCPP_INFO(this->get_logger(), "============================================================");
    RCLCPP_INFO(this->get_logger(), "é…ç½®æ–‡ä»¶: %s", config_file.c_str());
    RCLCPP_INFO(this->get_logger(), "å›¾åƒå°ºå¯¸: %dx%d", im_shape_.first, im_shape_.second);
    RCLCPP_INFO(this->get_logger(), "ç›¸æœºæ•°é‡: %zu", camera_configs_.size());
    for (size_t i = 0; i < camera_configs_.size(); ++i) {
        RCLCPP_INFO(this->get_logger(), "  ç›¸æœºæ˜ å°„å…³ç³»%zu: %s -> %s", 
                   i, camera_configs_[i].topic_name.c_str(), camera_configs_[i].camera_name.c_str());
    }
    RCLCPP_INFO(this->get_logger(), "è¾“å…¥/è¾“å‡ºFPS: %d/%d", input_fps_, output_fps_);
    RCLCPP_INFO(this->get_logger(), "å¤„ç†é—´éš”: %d ms", skip_interval_ms_);
    RCLCPP_INFO(this->get_logger(), "åŒæ­¥é˜Ÿåˆ—: %d, åŒæ­¥è¯¯å·®: %.3fs", sync_queue_size_, sync_slop_);
    RCLCPP_INFO(this->get_logger(), "============================================================");
    
    // åˆå§‹åŒ–å¤„ç†é˜Ÿåˆ—å’Œäº’æ–¥é”
    size_t num_cameras = camera_configs_.size();
    input_queues_.resize(num_cameras);
    output_queues_.resize(num_cameras);
    // input_queue_mutexes_.resize(num_cameras);
    // output_queue_mutexes_.resize(num_cameras);
    // input_queue_cvs_.resize(num_cameras);
    fus_trajectory_.resize(num_cameras);
    
    // 1. æ­£ç¡®åˆå§‹åŒ–äº’æ–¥é”å’Œæ¡ä»¶å˜é‡ï¼ˆä½¿ç”¨emplace_backï¼‰
    input_queue_mutexes_.clear();
    output_queue_mutexes_.clear();
    input_queue_cvs_.clear();
    for (size_t i = 0; i < num_cameras; ++i) {
        input_queue_mutexes_.emplace_back(std::make_shared<std::mutex>());
        output_queue_mutexes_.emplace_back(std::make_shared<std::mutex>());
        input_queue_cvs_.emplace_back(std::make_shared<std::condition_variable>());
    }

    // åˆå§‹åŒ–æ¯ä¸ªç›¸æœºçš„æœ€æ–°å¤„ç†å›¾åƒä¸ºç©ºç™½å›¾åƒ
    cv::Mat blank_image = cv::Mat::zeros(im_shape_.second, im_shape_.first, CV_8UC3);
    for (size_t i = 0; i < num_cameras; ++i) {
        latest_processed_images_[camera_configs_[i].topic_name] = blank_image.clone();
    }
    
    // åˆ›å»ºworkerçº¿ç¨‹ï¼ˆæ¯ä¸ªç›¸æœºä¸€ä¸ªçº¿ç¨‹ï¼Œç­‰ä»·äºPythonçš„å¤šè¿›ç¨‹workerï¼‰
    worker_threads_.reserve(num_cameras);
    for (size_t i = 0; i < num_cameras; ++i) {
        worker_threads_.emplace_back(&DeepSORVFNode::worker_thread, this, i);
    }
    
    // åˆ›å»ºæ˜¾ç¤ºçª—å£
    cv::namedWindow(window_name_, cv::WINDOW_NORMAL);
    
    // é…ç½®QoS
    rclcpp::QoS image_qos(3);
    image_qos.reliability(rclcpp::ReliabilityPolicy::BestEffort);
    image_qos.history(rclcpp::HistoryPolicy::KeepLast);
    
    // åˆ›å»ºç›¸æœºå›¾åƒè®¢é˜…å™¨ï¼ˆç›®å‰åªæ”¯æŒ3ä¸ªç›¸æœºï¼‰
    if (num_cameras >= 3) {
        camera_subscribers_.resize(3);
        camera_subscribers_[0] = std::make_shared<message_filters::Subscriber<sensor_msgs::msg::Image>>(
            this, camera_configs_[0].topic_name, image_qos.get_rmw_qos_profile());
        camera_subscribers_[1] = std::make_shared<message_filters::Subscriber<sensor_msgs::msg::Image>>(
            this, camera_configs_[1].topic_name, image_qos.get_rmw_qos_profile());
        camera_subscribers_[2] = std::make_shared<message_filters::Subscriber<sensor_msgs::msg::Image>>(
            this, camera_configs_[2].topic_name, image_qos.get_rmw_qos_profile());
        
        // åˆ›å»ºæ—¶é—´åŒæ­¥å™¨
        using SyncPolicy = message_filters::sync_policies::ApproximateTime<
            sensor_msgs::msg::Image, sensor_msgs::msg::Image, sensor_msgs::msg::Image>;
        
        // ApproximateTimeç­–ç•¥æ„é€ å‡½æ•°å‚æ•°ï¼šæ—¶é—´çª—å£ï¼ˆçº³ç§’ï¼‰
        // å°†sync_slop_ï¼ˆç§’ï¼‰è½¬æ¢ä¸ºçº³ç§’
        uint32_t age_ns = static_cast<uint32_t>(sync_slop_ * 1e9);
        sync_ = std::make_shared<message_filters::Synchronizer<SyncPolicy>>(
            SyncPolicy(age_ns),
            *camera_subscribers_[0], *camera_subscribers_[1], *camera_subscribers_[2]);
        
        sync_->registerCallback(std::bind(&DeepSORVFNode::synchronized_camera_callback, this,
            std::placeholders::_1, std::placeholders::_2, std::placeholders::_3));
    } else {
        RCLCPP_ERROR(this->get_logger(), "å½“å‰åªæ”¯æŒ3ä¸ªç›¸æœºï¼Œä½†é…ç½®ä¸­åªæœ‰ %zu ä¸ª", num_cameras);
    }
    
    // è®¢é˜…AISå’ŒGNSSæ•°æ®
    aisbatch_subscriber_ = this->create_subscription<marnav_interfaces::msg::AisBatch>(
        ais_batch_topic_, 10,
        std::bind(&DeepSORVFNode::aisbatch_callback, this, std::placeholders::_1));
    
    gnss_subscriber_ = this->create_subscription<marnav_interfaces::msg::Gnss>(
        gnss_topic_, 10,
        std::bind(&DeepSORVFNode::gnss_callback, this, std::placeholders::_1));
    
    // åˆ›å»ºå®šæ—¶å™¨
    window_timer_ = this->create_wall_timer(
        std::chrono::milliseconds(1000 / output_fps_),
        std::bind(&DeepSORVFNode::refresh_window_callback, this));
    
    trajectory_publish_timer_ = this->create_wall_timer(
        1s,
        std::bind(&DeepSORVFNode::publish_trajectory_callback, this));
    
    // åˆ›å»ºè½¨è¿¹å‘å¸ƒå™¨
    fus_trajectory_publisher_ = this->create_publisher<marnav_interfaces::msg::VisiableTraBatch>(
        fus_trajectory_topic_, image_qos);
}

DeepSORVFNode::~DeepSORVFNode()
{
    // åœæ­¢workerçº¿ç¨‹
    running_ = false;
    for (size_t i = 0; i < input_queue_cvs_.size(); ++i) {
        input_queue_cvs_[i]->notify_all();
    }
    
    // ç­‰å¾…æ‰€æœ‰çº¿ç¨‹ç»“æŸ
    for (auto& thread : worker_threads_) {
        if (thread.joinable()) {
            thread.join();
        }
    }
    
    cv::destroyAllWindows();
}

bool DeepSORVFNode::loadConfig(const std::string& config_file)
{
    try {
        YAML::Node config = YAML::LoadFile(config_file);
        
        // åŠ è½½ç›¸æœºé…ç½®
        if (!config["camera"]) {
            RCLCPP_ERROR(this->get_logger(), "é…ç½®æ–‡ä»¶ä¸­æœªæ‰¾åˆ°'camera'èŠ‚ç‚¹");
            return false;
        }
        
        const YAML::Node& camera_config = config["camera"];
        auto wh = camera_config["width_height"].as<std::vector<int>>();
        im_shape_ = {wh[0], wh[1]};
        angle_between_cameras_ = camera_config["angle_between_cameras"].as<double>(60.0);
        max_dis_ = std::min(im_shape_.first, im_shape_.second) / 2;
        
        camera_configs_.clear();
        for (const auto& cam : camera_config["camera_parameters"]) {
            CameraConfig cam_cfg;
            cam_cfg.camera_name = cam["camera_name"].as<std::string>();
            cam_cfg.topic_name = cam["topic_name"].as<std::string>();
            cam_cfg.camera_index = cam["camera_index"].as<int>();
            
            const auto& matrix = cam["camera_matrix"];
            cam_cfg.fov_hor = matrix["fov_hor"].as<double>();
            cam_cfg.fov_ver = matrix["fov_ver"].as<double>();
            cam_cfg.fx = matrix["fx"].as<double>();
            cam_cfg.fy = matrix["fy"].as<double>();
            cam_cfg.u0 = matrix["u0"].as<double>();
            cam_cfg.v0 = matrix["v0"].as<double>();
            
            if (cam["distortion_coefficients"]) {
                const auto& dist = cam["distortion_coefficients"];
                cam_cfg.k1 = dist["k1"].as<double>();
                cam_cfg.k2 = dist["k2"].as<double>();
                cam_cfg.k3 = dist["k3"].as<double>();
                cam_cfg.k4 = dist["k4"].as<double>();
            }
            
            camera_configs_.push_back(cam_cfg);
            camera_name_mapping_[cam_cfg.topic_name] = cam_cfg.camera_name;
        }
        
        // åŠ è½½AISé…ç½®
        if (config["ais"]) {
            ais_batch_topic_ = config["ais"]["ais_batch_pub_topic"].as<std::string>("/ais_batch_topic");
        } else {
            ais_batch_topic_ = "/ais_batch_topic";
        }
        
        // åŠ è½½GNSSé…ç½®
        if (config["gnss"]) {
            gnss_topic_ = config["gnss"]["gnss_pub_topic"].as<std::string>("/gnss_topic");
        } else {
            gnss_topic_ = "/gnss_topic";
        }
        
        // åŠ è½½DeepSORVFé…ç½®
        if (config["DeepSORVF"]) {
            const auto& ds_config = config["DeepSORVF"];
            fus_trajectory_topic_ = ds_config["fus_trajectory_topic"].as<std::string>("/fus_trajectory_topic");
            input_fps_ = ds_config["input_fps"].as<int>(20);
            output_fps_ = ds_config["output_fps"].as<int>(10);
            sync_queue_size_ = ds_config["sync_queue_size"].as<int>(10);
            sync_slop_ = ds_config["sync_slop"].as<double>(0.1);
            skip_interval_ms_ = ds_config["skip_interval"].as<int>(1000);
            camera_type_ = ds_config["camera_type"].as<std::string>("normal");
        } else {
            fus_trajectory_topic_ = "/fus_trajectory_topic";
            input_fps_ = 20;
            output_fps_ = 10;
            sync_queue_size_ = 10;
            sync_slop_ = 0.1;
            skip_interval_ms_ = 1000;
            camera_type_ = "normal";
        }
        
        t_ms_ = 1000 / input_fps_;
        
        return true;
    } catch (const YAML::Exception& e) {
        RCLCPP_ERROR(this->get_logger(), "è§£æYAMLé…ç½®æ–‡ä»¶å¤±è´¥: %s", e.what());
        return false;
    } catch (const std::exception& e) {
        RCLCPP_ERROR(this->get_logger(), "è¯»å–é…ç½®æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: %s", e.what());
        return false;
    }
}

int64_t DeepSORVFNode::timestamp_to_ms(const builtin_interfaces::msg::Time& stamp)
{
    return static_cast<int64_t>(stamp.sec) * 1000 + stamp.nanosec / 1000000;
}

std::vector<AISData> DeepSORVFNode::convert_ais_batch(const marnav_interfaces::msg::AisBatch::SharedPtr& msg)
{
    std::vector<AISData> result;
    for (const auto& ais : msg->ais_list) {
        AISData data;
        data.mmsi = ais.mmsi;
        data.lon = ais.lon;
        data.lat = ais.lat;
        data.speed = ais.speed;
        data.course = ais.course;
        data.heading = ais.heading;
        data.type = ais.type;
        data.timestamp_ms = timestamp_to_ms(ais.timestamp);
        result.push_back(data);
    }
    return result;
}

void DeepSORVFNode::synchronized_camera_callback(
    const sensor_msgs::msg::Image::ConstSharedPtr& img1,
    const sensor_msgs::msg::Image::ConstSharedPtr& img2,
    const sensor_msgs::msg::Image::ConstSharedPtr& img3)
{
    // æ£€æŸ¥ç›¸æœºä½ç½®å‚æ•°æ˜¯å¦å·²åˆå§‹åŒ–
    {
        std::lock_guard<std::mutex> lock(camera_pos_para_mutex_);
        if (camera_pos_para_.empty()) {
            RCLCPP_WARN_THROTTLE(this->get_logger(), *this->get_clock(), 5000,
                "ç­‰å¾…GNSSæ•°æ®æ›´æ–°ç›¸æœºä½ç½®å‚æ•°ï¼Œæš‚ä¸å¤„ç†å›¾åƒå¸§");
            return;
        }
    }
    
    // æ£€æŸ¥AISæ•°æ®ï¼ˆéå¿…éœ€ï¼Œä»…è­¦å‘Šï¼‰
    {
        std::lock_guard<std::mutex> lock(aisbatch_mutex_);
        if (aisbatch_cache_.empty()) {
            RCLCPP_WARN_THROTTLE(this->get_logger(), *this->get_clock(), 5000,
                "æœªæ”¶åˆ°AISæ•°æ®ï¼Œå°†ä»…ä½¿ç”¨è§†è§‰è·Ÿè¸ªæ¨¡å¼");
        }
    }
    
    // è½¬æ¢å›¾åƒ
    std::vector<cv::Mat> cv_images;
    try {
        cv_bridge::CvImagePtr cv_ptr1 = cv_bridge::toCvCopy(img1, sensor_msgs::image_encodings::BGR8);
        cv_bridge::CvImagePtr cv_ptr2 = cv_bridge::toCvCopy(img2, sensor_msgs::image_encodings::BGR8);
        cv_bridge::CvImagePtr cv_ptr3 = cv_bridge::toCvCopy(img3, sensor_msgs::image_encodings::BGR8);
        cv_images.push_back(cv_ptr1->image);
        cv_images.push_back(cv_ptr2->image);
        cv_images.push_back(cv_ptr3->image);
    } catch (cv_bridge::Exception& e) {
        RCLCPP_ERROR(this->get_logger(), "cv_bridgeå¼‚å¸¸: %s", e.what());
        return;
    }
    
    int64_t current_timestamp = timestamp_to_ms(img1->header.stamp);
    
    // è·å–AISæ•°æ®å’Œç›¸æœºä½ç½®å‚æ•°
    std::vector<AISData> ais_batch;
    std::map<int, CameraPosPara> camera_pos_para;
    {
        std::lock_guard<std::mutex> lock(aisbatch_mutex_);
        ais_batch = aisbatch_cache_;
    }
    {
        std::lock_guard<std::mutex> lock(camera_pos_para_mutex_);
        camera_pos_para = camera_pos_para_;
    }
    
    // ä¸ºæ¯ä¸ªç›¸æœºæäº¤ä»»åŠ¡
    for (size_t cam_idx = 0; cam_idx < camera_configs_.size() && cam_idx < cv_images.size(); ++cam_idx) {
        // æ£€æŸ¥ç›¸æœºä½ç½®å‚æ•°
        if (camera_pos_para.find(cam_idx) == camera_pos_para.end()) {
            RCLCPP_WARN(this->get_logger(), "camera_pos_para[%zu] ç¼ºå¤±ï¼Œè·³è¿‡è¯¥å¸§", cam_idx);
            continue;
        }
        
        ProcessingTask task;
        task.cam_idx = cam_idx;
        task.cv_image = cv_images[cam_idx].clone();
        task.current_timestamp_ms = current_timestamp;
        task.ais_batch = ais_batch;
        task.camera_pos_para = camera_pos_para[cam_idx];
        
        // æäº¤åˆ°è¾“å…¥é˜Ÿåˆ—
        {
            std::unique_lock<std::mutex> lock(*input_queue_mutexes_[cam_idx]);
            if (input_queues_[cam_idx].size() < MAX_QUEUE_SIZE) {
                input_queues_[cam_idx].push(task);
                input_queue_cvs_[cam_idx]->notify_one();
            } else {
                RCLCPP_DEBUG(this->get_logger(), "å¤šçº¿ç¨‹è¾“å…¥é˜Ÿåˆ—æ»¡ï¼Œä¸¢å¼ƒ cam%zu å½“å‰å¸§", cam_idx);
            }
        }
    }
}

void DeepSORVFNode::aisbatch_callback(const marnav_interfaces::msg::AisBatch::SharedPtr msg)
{
    std::vector<AISData> converted = convert_ais_batch(msg);
    
    std::lock_guard<std::mutex> lock(aisbatch_mutex_);
    aisbatch_cache_ = converted;
    
    // é™åˆ¶ç¼“å­˜å¤§å°ï¼ˆæœ€å¤š100æ¡ï¼‰
    if (aisbatch_cache_.size() > 100) {
        aisbatch_cache_.erase(aisbatch_cache_.begin(), 
                             aisbatch_cache_.begin() + (aisbatch_cache_.size() - 100));
    }
}

void DeepSORVFNode::gnss_callback(const marnav_interfaces::msg::Gnss::SharedPtr msg)
{
    std::lock_guard<std::mutex> lock(camera_pos_para_mutex_);
    
    // æ›´æ–°æ¯ä¸ªç›¸æœºçš„ä½ç½®å‚æ•°
    for (size_t idx = 0; idx < camera_configs_.size(); ++idx) {
        // è®¡ç®—æ°´å¹³æœå‘ï¼ˆä¸­é—´ç›¸æœºä¸å˜ï¼Œå·¦å³ç›¸æœºè°ƒæ•´Â±Nåº¦ï¼‰
        double horizontal_orientation = fmod(msg->horizontal_orientation + 
            (static_cast<int>(idx) - 1) * angle_between_cameras_, 360.0);
        
        CameraPosPara para;
        para.longitude = msg->longitude;
        para.latitude = msg->latitude;
        para.horizontal_orientation = horizontal_orientation;
        para.vertical_orientation = msg->vertical_orientation;
        para.camera_height = msg->camera_height;
        
        // ä»ç›¸æœºé…ç½®ä¸­è·å–å†…å‚
        para.fov_hor = camera_configs_[idx].fov_hor;
        para.fov_ver = camera_configs_[idx].fov_ver;
        para.fx = camera_configs_[idx].fx;
        para.fy = camera_configs_[idx].fy;
        para.u0 = camera_configs_[idx].u0;
        para.v0 = camera_configs_[idx].v0;
        
        // å¦‚æœæ˜¯é±¼çœ¼ç›¸æœºï¼Œæ·»åŠ ç•¸å˜ç³»æ•°
        if (camera_type_ == "fisheye") {
            para.k1 = camera_configs_[idx].k1;
            para.k2 = camera_configs_[idx].k2;
            para.k3 = camera_configs_[idx].k3;
            para.k4 = camera_configs_[idx].k4;
        }
        
        camera_pos_para_[idx] = para;
    }
}

void DeepSORVFNode::worker_thread(int cam_idx)
{
    // Workerçº¿ç¨‹å¤„ç†å‡½æ•°ï¼ˆç­‰ä»·äºPythonçš„multi_proc_workerï¼‰
    // æŒ‰ç…§Pythonç‰ˆæœ¬çš„é€»è¾‘å®ç°AIS/VIS/FUS/DRAWå¤„ç†
    
    RCLCPP_INFO(this->get_logger(), "Workerçº¿ç¨‹ %d å·²å¯åŠ¨", cam_idx);
    
    // åˆ›å»ºAISPROå®ä¾‹ï¼ˆç±»ä¼¼Python: aispro = AISPRO(im_shape, t)ï¼‰
    AISPRO aispro(im_shape_, t_ms_);
    // TODO: åç»­éœ€è¦æ·»åŠ VISPRO, FUSPRO, DRAWå®ä¾‹
    // VISPRO vispro(1, 0, t_ms_);
    // FUSPRO fuspro(max_dis_, im_shape_, t_ms_);
    // DRAW dra(im_shape_, t_ms_);
    
    // ç¼“å­˜ä¸Šä¸€çª—å£çš„èåˆè½¨è¿¹ï¼ˆç±»ä¼¼Python: Last_Visiable_Tra = pd.DataFrame()ï¼‰
    std::vector<VisiableTraData> last_visiable_tra;
    // è®°å½•ä¸Šæ¬¡å¤„ç†æ—¶æ‰€å±çš„æ—¶é—´çª—å£ï¼ˆç±»ä¼¼Python: last_processed_window = -1ï¼‰
    int64_t last_processed_window = -1;
    
    while (running_) {
        ProcessingTask task;
        bool has_task = false;
        
        // ä»è¾“å…¥é˜Ÿåˆ—è·å–ä»»åŠ¡
        {
            std::unique_lock<std::mutex> lock(*input_queue_mutexes_[cam_idx]);
            input_queue_cvs_[cam_idx]->wait(lock, [this, cam_idx, &has_task, &task]() {
                if (!running_) return true;
                if (!input_queues_[cam_idx].empty()) {
                    task = input_queues_[cam_idx].front();
                    input_queues_[cam_idx].pop();
                    has_task = true;
                    return true;
                }
                return false;
            });
        }
        
        if (!running_ && !has_task) break;
        if (!has_task) continue;
        
        auto start_time = std::chrono::steady_clock::now();
        
        try {
            // è®¡ç®—å½“å‰æ—¶é—´æˆ³å±äºå“ªä¸ªçª—å£ï¼ˆç±»ä¼¼Python: current_window = current_timestamp // skip_intervalï¼‰
            int64_t current_window = task.current_timestamp_ms / skip_interval_ms_;
            
            // åªæœ‰è¿›å…¥æ–°çª—å£æ—¶æ‰å¤„ç†ï¼ˆç±»ä¼¼Python: process_ais_vis_fus = (current_window != last_processed_window)ï¼‰
            bool process_ais_vis_fus = (current_window != last_processed_window);
            
            ProcessingResult result;
            result.cam_idx = cam_idx;
            result.timestamp_ms = task.current_timestamp_ms;
            
            if (process_ais_vis_fus) {
                // 1. AISå¤„ç†ï¼ˆç±»ä¼¼Python: AIS_vis, AIS_cur = aispro.process(...)ï¼‰
                std::vector<AISVisData> ais_vis;
                std::vector<AISData> ais_cur;
                aispro.process(task.ais_batch, task.camera_pos_para, 
                              task.current_timestamp_ms, camera_type_, 
                              ais_vis, ais_cur);
                
                // TODO: 2. VISå¤„ç†ï¼ˆç±»ä¼¼Python: Vis_tra, Vis_cur = vispro.feedCap(...)ï¼‰
                // std::vector<VisData> vis_tra, vis_cur;
                // vispro.feedCap(task.cv_image, ais_vis, bin_inf, task.current_timestamp_ms, vis_tra, vis_cur);
                
                // TODO: 3. FUSå¤„ç†ï¼ˆç±»ä¼¼Python: Fus_tra, updated_bin = fuspro.fusion(...)ï¼‰
                // std::vector<FusTraData> fus_tra;
                // fuspro.fusion(ais_vis, ais_cur, vis_tra, vis_cur, task.current_timestamp_ms, fus_tra);
                
                // TODO: 4. DRAWå¤„ç†ï¼ˆç±»ä¼¼Python: im, Visiable_Tra = dra.draw_match_traj(...)ï¼‰
                // ç›®å‰æš‚æ—¶åªå¤åˆ¶åŸå›¾ï¼Œç­‰å¾…DRAWå®ç°åå†æ›¿æ¢
                cv::Mat processed_image = task.cv_image.clone();
                
                // å°†AIS_visè½¬æ¢ä¸ºVisiableTraDataï¼ˆç›®å‰åªåŒ…å«AISæ•°æ®ï¼Œç­‰å¾…FUSå®Œæˆåä¼šæœ‰å®Œæ•´çš„è½¨è¿¹æ•°æ®ï¼‰
                std::vector<VisiableTraData> visiable_tra_list;
                for (const auto& vis : ais_vis) {
                    VisiableTraData tra;
                    tra.cam_idx = cam_idx;
                    tra.timestamp_ms = vis.timestamp_ms * 1000;  // AISVisDataä¸­timestamp_msæ˜¯ç§’ï¼Œè½¬æ¢ä¸ºæ¯«ç§’
                    tra.ais = 1;  // è¡¨ç¤ºåŒ…å«AISä¿¡æ¯
                    tra.mmsi = vis.mmsi;
                    tra.ship_type = "";  // TODO: ä»typeå­—æ®µè·å–èˆ¹åªç±»å‹ï¼Œç›®å‰ä¸ºç©º
                    tra.sog = static_cast<float>(vis.speed);
                    tra.cog = static_cast<float>(vis.course);
                    tra.lat = static_cast<float>(vis.lat);
                    tra.lon = static_cast<float>(vis.lon);
                    // TODO: éœ€è¦å®é™…çš„æ£€æµ‹æ¡†åæ ‡ï¼Œç›®å‰ä½¿ç”¨å›¾åƒåæ ‡ç‚¹å‘¨å›´50åƒç´ çš„å ä½æ¡†
                    tra.box_x1 = static_cast<float>(std::max(0, vis.x - 50));
                    tra.box_y1 = static_cast<float>(std::max(0, vis.y - 50));
                    tra.box_x2 = static_cast<float>(std::min(im_shape_.first - 1, vis.x + 50));
                    tra.box_y2 = static_cast<float>(std::min(im_shape_.second - 1, vis.y + 50));
                    visiable_tra_list.push_back(tra);
                }
                
                result.processed_image = processed_image;
                result.visiable_tra_list = visiable_tra_list;
                last_visiable_tra = visiable_tra_list;  // æ›´æ–°ç¼“å­˜
                last_processed_window = current_window;  // æ›´æ–°çª—å£æ ‡è®°
            } else {
                // è·³è¿‡å¤„ç†ï¼Œç›´æ¥ä½¿ç”¨åŸå›¾ï¼ˆç±»ä¼¼Python: im = dra.draw_no_match_traj(cv_image)ï¼‰
                result.processed_image = task.cv_image.clone();
                result.visiable_tra_list = last_visiable_tra;  // ä½¿ç”¨ç¼“å­˜çš„è½¨è¿¹
            }
            
            auto end_time = std::chrono::steady_clock::now();
            result.time_cost = std::chrono::duration<double>(end_time - start_time).count();
            
            // å°†ç»“æœæ”¾å…¥è¾“å‡ºé˜Ÿåˆ—
            {
                std::unique_lock<std::mutex> lock(*output_queue_mutexes_[cam_idx]);
                if (output_queues_[cam_idx].size() < MAX_QUEUE_SIZE) {
                    output_queues_[cam_idx].push(result);
                } else {
                    RCLCPP_DEBUG(this->get_logger(), "è¾“å‡ºé˜Ÿåˆ—æ»¡ï¼Œä¸¢å¼ƒ cam%d çš„ç»“æœ", cam_idx);
                }
            }
        } catch (const std::exception& e) {
            RCLCPP_ERROR(this->get_logger(), "Worker cam%d å¤„ç†å‡ºé”™: %s", cam_idx, e.what());
            // ç»§ç»­å¤„ç†ä¸‹ä¸€å¸§ï¼Œä¸ä¸­æ–­çº¿ç¨‹
        }
    }
    
    RCLCPP_INFO(this->get_logger(), "Workerçº¿ç¨‹ %d å·²é€€å‡º", cam_idx);
}

void DeepSORVFNode::refresh_window_callback()
{
    // å›æ”¶workerçº¿ç¨‹çš„è¾“å‡ºç»“æœ
    for (size_t cam_idx = 0; cam_idx < camera_configs_.size(); ++cam_idx) {
        std::queue<ProcessingResult> temp_results;
        
        // ä»è¾“å‡ºé˜Ÿåˆ—å–å‡ºæ‰€æœ‰ç»“æœ
        {
            std::unique_lock<std::mutex> lock(*output_queue_mutexes_[cam_idx]);
            temp_results = output_queues_[cam_idx];
            while (!output_queues_[cam_idx].empty()) {
                output_queues_[cam_idx].pop();
            }
        }
        
        // å¤„ç†ç»“æœ
        ProcessingResult latest_result;
        bool has_result = false;
        while (!temp_results.empty()) {
            latest_result = temp_results.front();
            temp_results.pop();
            has_result = true;
        }
        
        if (has_result) {
            // æ›´æ–°å¤„ç†åçš„å›¾åƒ
            {
                std::lock_guard<std::mutex> lock(processed_images_mutex_);
                latest_processed_images_[camera_configs_[cam_idx].topic_name] = 
                    latest_result.processed_image.clone();
            }
            
            // æ›´æ–°èåˆè½¨è¿¹
            {
                std::lock_guard<std::mutex> lock(fus_trajectory_mutex_);
                fus_trajectory_[cam_idx] = latest_result.visiable_tra_list;
            }
        }
    }
    
    // æ‹¼æ¥å›¾åƒå¹¶æ˜¾ç¤º
    std::vector<cv::Mat> images_to_concat;
    {
        std::lock_guard<std::mutex> lock(processed_images_mutex_);
        
        cv::Size target_size;
        bool all_valid = true;
        
        for (const auto& config : camera_configs_) {
            auto it = latest_processed_images_.find(config.topic_name);
            if (it == latest_processed_images_.end() || it->second.empty()) {
                all_valid = false;
                break;
            }
            
            if (target_size.width == 0) {
                target_size = it->second.size();
            } else if (it->second.size() != target_size) {
                // è°ƒæ•´å›¾åƒå°ºå¯¸ä»¥åŒ¹é…
                cv::Mat resized;
                cv::resize(it->second, resized, target_size);
                images_to_concat.push_back(resized);
                continue;
            }
            
            images_to_concat.push_back(it->second);
        }
        
        if (all_valid && images_to_concat.size() == camera_configs_.size()) {
            try {
                cv::Mat stitched_image;
                cv::hconcat(images_to_concat, stitched_image);
                cv::putText(stitched_image, "Unified Time: " + std::to_string(std::chrono::system_clock::now().time_since_epoch().count()), cv::Point(10, 30), cv::FONT_HERSHEY_SIMPLEX, 1, cv::Scalar(0, 0, 255), 2);
                cv::imshow(window_name_, stitched_image);
                cv::waitKey(1);
            } catch (const cv::Exception& e) {
                RCLCPP_ERROR(this->get_logger(), "å›¾åƒæ‹¼æ¥å¤±è´¥: %s", e.what());
            }
        }
    }
}

void DeepSORVFNode::publish_trajectory_callback()
{
    // å®šæ—¶å‘å¸ƒèåˆè½¨è¿¹ï¼ˆ1ç§’ä¸€æ¬¡ï¼‰
    marnav_interfaces::msg::VisiableTraBatch msg_batch;
    msg_batch.visiable_tra_list.clear();
    
    std::lock_guard<std::mutex> lock(fus_trajectory_mutex_);
    
    for (size_t cam_idx = 0; cam_idx < fus_trajectory_.size(); ++cam_idx) {
        if (fus_trajectory_[cam_idx].empty()) {
            continue;
        }
        
        // ä½¿ç”¨ç¬¬ä¸€ä¸ªè½¨è¿¹çš„æ—¶é—´æˆ³ä½œä¸ºbatchçš„æ—¶é—´æˆ³
        if (!fus_trajectory_[cam_idx].empty()) {
            int64_t batch_timestamp_ms = fus_trajectory_[cam_idx][0].timestamp_ms;
            msg_batch.timestamp.sec = batch_timestamp_ms / 1000;
            msg_batch.timestamp.nanosec = (batch_timestamp_ms % 1000) * 1000000;
        }
        
        for (const auto& tra : fus_trajectory_[cam_idx]) {
            marnav_interfaces::msg::VisiableTra msg;
            
            // ä½¿ç”¨æ˜ å°„åçš„ç›¸æœºåç§°
            std::string topic_name = camera_configs_[cam_idx].topic_name;
            msg.camera_name = camera_name_mapping_[topic_name];
            
            // æ—¶é—´æˆ³
            msg.timestamp.sec = tra.timestamp_ms / 1000;
            msg.timestamp.nanosec = (tra.timestamp_ms % 1000) * 1000000;
            
            // AISç›¸å…³å­—æ®µ
            msg.ais = tra.ais;
            msg.mmsi = tra.mmsi;
            msg.ship_type = tra.ship_type.empty() ? "cargo ship" : tra.ship_type;
            
            // é€Ÿåº¦å’Œèˆªå‘
            msg.sog = tra.sog >= 0.0f ? tra.sog : 0.0f;
            msg.cog = tra.cog >= 0.0f ? tra.cog : 0.0f;
            
            // ç»çº¬åº¦
            msg.lat = tra.lat;
            msg.lon = tra.lon;
            
            // æ£€æµ‹æ¡†åæ ‡
            msg.box_x1 = tra.box_x1;
            msg.box_y1 = tra.box_y1;
            msg.box_x2 = tra.box_x2;
            msg.box_y2 = tra.box_y2;
            
            msg_batch.visiable_tra_list.push_back(msg);
        }
    }
    
    // åªæœ‰åœ¨æœ‰æ•°æ®æ—¶æ‰å‘å¸ƒ
    if (!msg_batch.visiable_tra_list.empty()) {
        fus_trajectory_publisher_->publish(msg_batch);
    }
}

int main(int argc, char* argv[])
{
    rclcpp::init(argc, argv);
    
    try {
        auto node = std::make_shared<DeepSORVFNode>();
        rclcpp::spin(node);
    } catch (const std::exception& e) {
        RCLCPP_ERROR(rclcpp::get_logger("main"), "èŠ‚ç‚¹å¼‚å¸¸: %s", e.what());
        return 1;
    }
    
    rclcpp::shutdown();
    return 0;
}
